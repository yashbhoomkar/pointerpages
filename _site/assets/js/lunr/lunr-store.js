var store = [{
        "title": "Secret Life of A DNS Query",
        "excerpt":"This article describes how a DNS query gets resolved. Though a website is loaded in just one-click on our devices, a lot of work goes on at the back end to render that webpage. Let’s see how it’s done.   Before you read further, these are the terms you need to get acquainted with:  Important Terms:   IP Address   An IP address is a unique address that identifies a device on the internet or a local network.   Query   A query is a message sent by the client to the server.   Cache   Computing component that transparently stores data so that future requests for that data can be served faster.   DNS - the Internet’s Directory Service   The browser needs to translate “www.blogger.com” to its corresponding IP address, because hostnames can consist of variable-length alphanumeric characters, they would be difficult to process by routers. For these reasons, hosts are also identified by so-called IP addresses.   DNS Resolver   Servers designed to receive DNS queries from web browsers and other applications.   Authoritative Name Servers   Servers where the DNS records are stored. Consists of root name servers, TLD servers and authoritative servers.      Interaction of DNS Servers:     Consider you click on the URL www.blogger.com           Browser first checks if IP address is present in its DNS cache, if not it calls the function present in the operating system to do DNS lookups. For E.g. on Linux that function is getaddrinfo.            The OS might also have a DNS cache, if it has, then the function first checks if IP address is present in this cache. If IP is still not found, the function sends request to a server called DNS resolver            The resolver checks if IP address is present in its cache, if not it contacts the root name server.            The root name server checks if IP is present in its cache, if yes, it sends the corresponding IP address, if not it replies with “I don’t know this name but ask the TLD server.”            The resolver then asks/queries the TLD server.            The TLD server checks if IP is present in its cache, if yes, it sends the corresponding IP address, if not it replies with “I don’t know this name but ask the Authoritative name server.”            The resolver then queries the authoritative name server.            The authoritative name server has the IP Address of the requested website in its database. It responds with the corresponding IP to the resolver.            The resolver/local DNS server then sends this IP to the OS.            This IP is communicated to the browser and it starts opening a TCP connection to the server.       As shown above, the DNS query is iterative in nature, as recursive queries put heavy load of name resolution in upper levels of hierarchy.    References:   James Kurose, Keith Ross, Computer Networking A Top-Down Approach, 7th Edition.  ","categories": ["networking"],
        "tags": ["networks","DNS"],
        "url": "/yashbhoomkar/networking/secret-life-of-a-dns-query/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "Creating Processes",
        "excerpt":"In this article I have tried to explain the important things that happen during a process creation. I always had doubts about     How a process is created in OS ?   From where does it all start ?   What happens when you start a process ?   What exactly is fork and exec ?   Let us see.   Process Heirarchy   Every process in Linux lives in a “process tree”. You can see that tree by running pstree in terminal. The root of the tree is init, with PID 1. Every process (except init) has a parent, and any process has many children.   Fork() System Call   The fork() system call is used to create a new process.The new process created by fork is called the child process.This function is called once but returns twice. The only difference in the returns is that the return value in the child is 0, whereas the return value in the parent is the process ID of the new child.The child - the process that is created is an (almost) exact copy of the calling process.   Exec() System Call  (Load into memory and then execute)   Fork creates a new process which is a clone of itself, but what if we want to change the course of the process? Then we use exec() syscall. Exec() replaces the current process — its text, data, heap, and stack segments — with a brand-new program from disk.   On Boot Up   On boot the kernel starts the init process, which then forks and execs the systems boot scripts. These fork and exec more programs, eventually ending up forking a login process.This is also known as process spawning which is carried out by these two systemcalls [fork &amp; exec] in the background.     Example code snippet of fork() and exec() in a C program:   int pid = fork(); // now I am split in two! aaaaugh! // who am I? I could be either the child or the parent if (pid == 0) {     // ok I am the child process     // ls will take over and I will be a totally different process      exec([\"ls\"]) } else if (pid == -1) {     // omg fork failed -- this is a disaster :( } else {     // ok i am the parent     // continue my business being a cool program     // I could wait for the child to finish if I want }    Now, if I want to start a process called ls to list all the files in a directory. The process starts out like this:   my parent      |- me   When I run fork(), a child is created which is a clone of myself.   my parent      |- me           |-- clone of me  Then my clone calls exec() that is, my child runs exec(\"ls\"). That leaves us with   my parent      |- me           |-- ls  Once ls exits I will be all alone by myself.(Almost)   my parent      |- me           |-- ls(zombie)  At this point ls is actually a zombie process! That means it’s dead, but it’s waiting around for the parent in case the parent wants to check on its (child’s) return value (using the wait system call.) Once I get its return value, I will really be all alone again.   my parent      |- me     The following paragraph from Operating Systems:Three Easy Pieces sums up the gist of the article:      The fork() system call is strange; its partner in crime, exec(), is not so normal either. What it does: given the name of an executable (e.g., wc), and some arguments (e.g., p3.c), it loads code (and static data) from that executable and overwrites its current code segment (and current static data) with it; the heap and stack and other parts of the memory space of the program are re-initialized. Then the OS simply runs that program, passing in any arguments as the argv of that process. Thus, it does not create a new process; rather, it transforms the currently running program (formerly p3) into a different running program (wc). After the exec() in the child, it is almost as if p3.c never ran; a successful call to exec() never returns.      References:   Remzi H. Arpaci-Dusseau_ Andrea C Arpaci-Dusseau - Operating Systems- Three Easy Pieces   Got this awesome concept from Julia Evans blog  ","categories": ["operating systems"],
        "tags": ["os","fork","process creation"],
        "url": "/yashbhoomkar/operating%20systems/process-creation/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "Debugging 101 - Love Your Bugs",
        "excerpt":"Errors and bugs are a necessary evil in any software developement field, and learning the art of debugging is a very vital step if you want to:      Improve your developer productivity   Write reliable code   In this article I have tried to document all the debugging methods that I learnt while working on my projects.      Whenever you encounter a bug in any of your code/installation it is always helpful to remember the following things:     The error happens for a logical reason - its never magic   Be confident that you can fix it   Being stuck is temporary   Now that you have these 3 things in your toolkit let us proceed for some debugging steps so that you can feel your inherent superpower. :)   Step 1: Read error message carefully   Error messages usually contain a lot of information about what went wrong. But they sometimes can be very large and overwhelming to read. You can  use these tricks to extract the necessary information from them:     Start fixing the first error message in case of multiple error messages. Fixing the first one often fixes the remaining errors   Search if any solution is available on the internet for the error   Step 2: Brainstorm possible reasons for the error   Now here I won’t be able to give exact reasons but some examples may include:     Is there something wrong with the server?   Am I using correct package version?   Have I followed all the instructions?(In case of errors in installations)   After finding possible reasons try to narrow it down to the most possible reason, also draw a diagram of the process if possible   Step 3: Investigate      Read the documentation (Important)   Add lots of print statements   Use a debugger   Look at logs   A meme that highlights the importance of reading the docs:      Step 4: Make complex things simple      Fix one problem at a time   Write clean code   Reduce randomness   Shorten your feedback/output loop (when you need to run the code many times)   Step 5: This also helps      Take a break   Ask a friend   Explain the error/bug out loud   Finding tools that make debugging easier - eg. debuggers, profilers, tracers, fuzzers, etc   Step 6: After fixing the bug     Celebrate - dance a little   Tell somebody what you learnt - that way you won’t forget it   Document your bug    Debugging can be an interesting adventure.   I would like to end this article by quoting Edsger Dijkstra:     ” Program testing can be used to show the presence of bugs, but never to show their absence! “   ","categories": ["tech-views"],
        "tags": ["bugs","debugging"],
        "url": "/yashbhoomkar/tech-views/debugging_guide/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "EduBuddy: A Full-Stack Smart Learning Platform",
        "excerpt":"🎯 Project Overview   EduBuddy is a full-stack smart learning and assessment platform designed to personalize education, track student progress, and foster collaboration. It leverages video-based content, dynamic quizzes, and real-time forums to promote adaptive and accessible learning for all.     🚀 Why EduBuddy?   Traditional educational platforms often fail to accommodate:     Diverse learning styles   Real-time analytics   Peer-to-peer collaboration   EduBuddy bridges these gaps by integrating:     📺 Embedded YouTube videos   🧪 Adaptive topic-wise assessments   📊 Individual performance tracking   💬 Interactive forums     🔧 Tech Stack                  Layer       Tech Used                       Frontend       React.js                 Backend       Express.js, Node.js                 Database       MongoDB                 APIs       YouTube API                 Real-Time       WebSocket.io                 Deployment       Vercel             ⭐ Key Features      🎥 YouTube-Driven Learning — Watch, pause, and resume lessons seamlessly   🧠 Conceptual Assessments — Evaluate understanding topic-wise   📈 Performance Dashboards — Real-time feedback with visual insights   💬 Discussion Forums — Students and mentors can ask, answer, and collaborate   👥 Peer-Created Spaces — Create custom discussion threads and topic clusters   🚀 Deployed on Vercel — Easy access with zero downtime   📱 Responsive Design — Learn on mobile, tablet, or desktop     🔍 How It Works      Student logs in and watches embedded videos through YouTube   After each topic, they take assessments   Their progress is tracked and displayed   If stuck, they can use forums to seek help   Results and feedback are instantly visualized     💡 Benefits      📚 Personalized and self-paced learning   🌎 Remote access and time flexibility   🤝 Strong student-instructor collaboration   🔍 Insights into learning gaps   👨‍🎓 Encourages ownership in student learning     📈 Future Enhancements      🎮 Gamified learning paths   📱 Native Android/iOS app   📚 LMS integrations (like Moodle, Canvas)   🤖 AI-based progress prediction   📡 Adaptive content recommendations     📌 Final Thoughts   EduBuddy demonstrates the power of full-stack web development when paired with purpose-driven goals. It’s more than a project — it’s a vision for modern education. By combining scalable tech with learner-centric design, EduBuddy helps bring smart education to everyone.   Interested in trying out or collaborating on EduBuddy?  Feel free to connect with me on LinkedIn or GitHub!    ","categories": ["full-stack","edtech"],
        "tags": ["react","express","mongodb","fullstack","vercel","education"],
        "url": "/yashbhoomkar/full-stack/edtech/edubuddy-fullstack-platform/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "What Happens When You Type www.google.com in Your Browser?",
        "excerpt":"🧠 Introduction   It’s a question every computer science student or aspiring engineer should be able to answer:      What actually happens when you type www.google.com into your browser and press Enter?    This blog breaks down the entire process — from keystroke to Google’s response — into understandable steps across networking, operating systems, and browser architecture.     🧩 Step-by-Step Breakdown   1. 🧾 URL Interpretation   The browser parses the URL:     Scheme: https   Host: www.google.com   Path: / (default)   It sees it needs a secure connection over HTTPS and prepares for a network request.     2. 🔍 DNS Resolution   To connect, the browser needs an IP address.      Checks local DNS cache   If not found, it asks the OS resolver   OS checks:            /etc/hosts       Local DNS cache       Configured DNS server (e.g. 8.8.8.8)           ➡️ Eventually resolves www.google.com to something like 142.250.193.68     3. 📶 TCP Handshake (with TLS)   Now the browser opens a connection to that IP on port 443 (HTTPS):      Initiates a 3-way TCP handshake:            SYN →       SYN-ACK ←       ACK →           Immediately followed by a TLS handshake for encryption:            ClientHello, ServerHello       Key exchange       Certificate verification       Encrypted channel established             4. 🌐 Sending the HTTP Request   The browser sends: GET / HTTP/1.1 Host: www.google.com User-Agent: Chrome/… Accept: /   yaml Copy Edit   Over an encrypted TLS connection.     5. 🖥️ Server Processes the Request      Google’s load balancer receives the request   Routes it to a healthy web server   The server reads the path, headers, and prepares a response     6. 📩 HTTP Response is Sent   The server replies with: HTTP/1.1 200 OK Content-Type: text/html Content-Length: 6000   yaml Copy Edit   Followed by the actual HTML document.     7. 🧱 Browser Renders the Page   The browser:     Parses the HTML   Downloads CSS, JS, images (multiple requests)   Constructs DOM + CSSOM → Render Tree   Renders the page pixel-by-pixel     🔁 Optimization Tricks      Caching: DNS, HTTP, and assets (to avoid redundant requests)   Persistent TCP connections (via keep-alive)   CDNs serve content faster from nearby locations   Service Workers can cache assets offline     💡 Final Thoughts   This seemingly simple action involves:     Browser engine logic   OS-level resolution   Network stack (TCP/IP, TLS)   Server-side processing   DOM rendering   Understanding this process is essential for full-stack, backend, and DevOps engineers.     🧪 Bonus Tip: Try running dig www.google.com or using browser DevTools to see DNS, network timing, and rendering in action!   Want a deep dive into TCP or TLS next? Drop me a topic!    ","categories": ["networking"],
        "tags": ["browser","dns","tcp","http","networking","interview"],
        "url": "/yashbhoomkar/networking/what-happens-when-you-type-google/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "What are WebSockets? Explained Simply",
        "excerpt":"🧠 Introduction   Have you ever used a chat app, live score update site, or real-time collaboration tool like Google Docs?   Chances are, WebSockets were involved.   WebSockets allow real-time, two-way communication between a browser (or client) and a server — something traditional HTTP was never designed for.     🧪 What is a WebSocket?      A WebSocket is a communication protocol that enables persistent, bi-directional, and full-duplex communication between a client and server over a single TCP connection.      🔁 Traditional HTTP vs WebSocket                  Feature       HTTP       WebSocket                       Request-Response       Client sends, server replies       Bi-directional messages                 Connection Type       Short-lived (stateless)       Persistent                 Overhead       High (headers in every request)       Low (handshake once)                 Real-time Updates       Requires polling or long-polling       Native real-time             🔧 How WebSocket Works   Step 1: HTTP Handshake   It starts with a normal HTTP request:   GET /chat HTTP/1.1 Host: server.com Upgrade: websocket Connection: Upgrade   csharp Copy Edit   If the server supports WebSockets, it responds with:   HTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade   yaml Copy Edit   Now the connection is upgraded to WebSocket.     Step 2: Real-Time Messaging Begins      Messages can now be sent in both directions at any time.   No need to wait for requests — the server can push data instantly!     ⚙️ WebSocket Use Cases      💬 Chat applications   📈 Stock price tickers   🎮 Multiplayer gaming   🧠 Collaborative editing   📡 Live notifications   🕐 Real-time dashboards     🛠 Example Code (Node.js)   ```js const WebSocket = require(‘ws’);   const server = new WebSocket.Server({ port: 8080 });   server.on(‘connection’, socket =&gt; {   console.log(‘Client connected’);   socket.on(‘message’, msg =&gt; {     console.log(Received: ${msg});     socket.send(Echo: ${msg});   });   socket.on(‘close’, () =&gt; {     console.log(‘Client disconnected’);   }); }); 🚧 Limitations Not ideal for very short-lived connections   Can be blocked by some proxies/firewalls   Requires fallback for older browsers (or use libraries like Socket.IO)   ✅ Alternatives &amp; Protocols Protocol\tWhen to Use HTTP\tOne-time fetches (GET/POST requests) WebSocket\tPersistent, full-duplex communication SSE (Server Sent Events)\tServer → Client only updates gRPC/WebRTC\tSpecial real-time/peer-to-peer needs 💡 Final Thoughts WebSockets changed the game by enabling true real-time web applications. They’re lightweight, fast, and perfect for scenarios where latency matters.   If you’re building anything interactive, collaborative, or instant — it’s time to speak WebSocket.  ","categories": ["networking"],
        "tags": ["websockets","real-time","tcp","http","socket","interview"],
        "url": "/yashbhoomkar/networking/what-are-websockets/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "Understanding Recursion and Stack Frames",
        "excerpt":"🧠 Introduction   Recursion is one of the most powerful — yet often misunderstood — concepts in computer science. It’s elegant, expressive, and frequently used in problems involving trees, graphs, backtracking, and more.   But what really happens under the hood when a function calls itself?   The answer lies in how stack frames work.     🔁 What is Recursion?      A function that calls itself in order to solve a smaller version of a problem.    It has two main parts:     Base Case: When to stop   Recursive Case: When the function calls itself   📝 Example: Factorial  ```python def factorial(n):     if n == 0:         return 1     return n * factorial(n - 1) Calling factorial(3) leads to:   matlab Copy Edit factorial(3) → 3 * factorial(2)               → 3 * (2 * factorial(1))               → 3 * (2 * (1 * factorial(0)))               → 3 * 2 * 1 * 1 = 6 🧱 The Role of Stack Frames Every time a function is called — including recursive calls — it gets its own stack frame:   A stack frame contains: Function parameters Local variables Return address This stack is called the call stack.   🧮 Visualizing the Stack for factorial(3) As the function calls build up:   scss Copy Edit TOP factorial(3) factorial(2) factorial(1) factorial(0) BOTTOM Each function waits for the next one to return a value.   Once the base case is hit (factorial(0)), the stack unwinds:   sql Copy Edit factorial(0) returns 1 factorial(1) returns 1 * 1 = 1 factorial(2) returns 2 * 1 = 2 factorial(3) returns 3 * 2 = 6 ⚠️ Why Stack Overflow Happens If your recursion has no base case or goes too deep, the call stack runs out of space:   python Copy Edit def infinite():     return infinite() ❌ This results in a stack overflow error, because the system can’t allocate any more stack frames.   💡 Tail Recursion Optimization (TCO) Some languages (like Lisp, Scheme, or optimized C compilers) support Tail Call Optimization where tail-recursive functions reuse the same stack frame.   Python and Java do not support TCO.   📊 Iterative vs Recursive Feature\tRecursion\tIteration Simpler logic\tOften yes\tSometimes complex Memory usage\tUses call stack\tUses loop variables Speed\tCan be slower\tUsually faster 📘 Common Recursive Problems Factorial, Fibonacci   Tree traversals (DFS)   Backtracking (N-Queens, Maze)   Divide and conquer (Merge Sort, Quick Sort)   🧠 Final Thoughts Recursion is not magic — it’s just functions stacked on top of each other until a base case is hit.   Understanding the call stack is the key to mastering recursion. With that mental model, recursive problems become much easier to debug and optimize.   Let me know if you’d like a visual animation or stack simulation in JavaScript for this topic!  ","categories": ["dsa"],
        "tags": ["recursion","stack","call stack","memory","dsa"],
        "url": "/yashbhoomkar/dsa/recursion-and-stackframes/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "Smart Email Routing",
        "excerpt":"Introduction   In the age of overflowing inboxes, email triaging can become a real pain—especially when you’re part of a fast-moving organization. Manually sorting and forwarding emails can waste hours every week. I decided to automate this task by building a Smart Email Routing System using the Gmail API and the LLaMA 3.2 model from Ollama.   The goal?  Build a GenAI-powered bot that can:     Read incoming emails.   Understand their context using LLaMA.   Decide who the email should go to.   Determine how urgent it is.   Route it intelligently—no human involved.   Let’s walk through how this system works.   How It Works   The architecture is pretty straightforward, but very powerful. Here’s the breakdown:   📨 1. Fetch Emails using Gmail API  Using OAuth 2.0 and the google-api-python-client, the system:     Authenticates securely using a token.json.   Connects to the Gmail inbox.   Fetches all unread emails from the INBOX.   Extracts the subject, sender, and message body (MIME decoded).   🧠 2. Pass Email to LLaMA 3.2 via Ollama  Once the email is fetched:     We combine the subject + body into a prompt.   Send it to a locally running LLaMA 3.2 model via Ollama CLI.   The prompt asks LLaMA to return:            To whom should this email be routed?       What is the severity level? (Low / Medium / High / Urgent)           🧾 3. Parse the Response  The model returns a JSON-like output such as:   {   \"route_to\": \"Legal Team\",   \"severity\": \"High\" }   This output is parsed and used in the next step.   🏷️ 4. Route and Tag the Email  Based on the model’s output:     Apply appropriate Gmail labels (e.g., to_legal, severity_high)   Optionally forward the email to the correct department   Archive or move it as needed   Implementation Code   Here’s the full implementation for this project:   import os import base64 import json import email from email.mime.text import MIMEText from googleapiclient.discovery import build from google_auth_oauthlib.flow import InstalledAppFlow from google.auth.transport.requests import Request from google.oauth2.credentials import Credentials import subprocess  # Define the scopes needed for Gmail API SCOPES = ['https://www.googleapis.com/auth/gmail.modify']  def authenticate_gmail():     \"\"\"     Authenticate with Gmail API using OAuth2     \"\"\"     creds = None     if os.path.exists('token.json'):         creds = Credentials.from_authorized_user_info(json.load(open('token.json')))          if not creds or not creds.valid:         if creds and creds.expired and creds.refresh_token:             creds.refresh(Request())         else:             flow = InstalledAppFlow.from_client_secrets_file(                 'credentials.json', SCOPES)             creds = flow.run_local_server(port=0)                  with open('token.json', 'w') as token:             token.write(creds.to_json())          return build('gmail', 'v1', credentials=creds)  def get_email_content(service, msg_id):     \"\"\"     Extract email content from message ID     \"\"\"     message = service.users().messages().get(userId='me', id=msg_id, format='full').execute()          headers = message['payload']['headers']     subject = next((header['value'] for header in headers if header['name'].lower() == 'subject'), '(No Subject)')     sender = next((header['value'] for header in headers if header['name'].lower() == 'from'), 'Unknown')          parts = [message['payload']]     body = \"\"          while parts:         part = parts.pop(0)                  if 'parts' in part:             parts.extend(part['parts'])                  if 'body' in part and 'data' in part['body']:             body_bytes = base64.urlsafe_b64decode(part['body']['data'])             body += body_bytes.decode('utf-8')          return {         'subject': subject,         'sender': sender,         'body': body,         'id': msg_id     }  def analyze_with_llama(subject, body):     \"\"\"     Send email content to LLaMA 3.2 via Ollama CLI for analysis     \"\"\"     prompt = f\"\"\"You are a smart email assistant.  Classify the following email and respond in JSON format with: 1. Who it should be routed to. 2. Severity level: Low, Medium, High, or Urgent.  Email: Subject: {subject} Body: {body} \"\"\"      # Execute Ollama command - adjust model name as needed     result = subprocess.run(         [\"ollama\", \"run\", \"llama3.2\", prompt],         capture_output=True,         text=True     )          # Extract JSON from response     try:         # Find JSON-like content in the output         response = result.stdout.strip()         start_idx = response.find('{')         end_idx = response.rfind('}') + 1                  if start_idx &gt;= 0 and end_idx &gt; start_idx:             json_str = response[start_idx:end_idx]             return json.loads(json_str)         else:             return {\"route_to\": \"Unknown\", \"severity\": \"Medium\"}     except Exception as e:         print(f\"Error parsing LLaMA response: {e}\")         return {\"route_to\": \"Unknown\", \"severity\": \"Medium\"}  def apply_routing(service, email_data, routing_info):     \"\"\"     Apply routing decisions to email (labels, forwarding, etc.)     \"\"\"     msg_id = email_data['id']     route_to = routing_info.get('route_to', 'Unknown').lower().replace(' ', '_')     severity = routing_info.get('severity', 'Medium').lower()          # Create labels if they don't exist     labels_to_apply = [f\"to_{route_to}\", f\"severity_{severity}\"]     existing_labels = service.users().labels().list(userId='me').execute().get('labels', [])     existing_label_names = [label['name'] for label in existing_labels]          for label_name in labels_to_apply:         if label_name not in existing_label_names:             label_object = {'name': label_name}             service.users().labels().create(userId='me', body=label_object).execute()          # Get label IDs for application     updated_labels = service.users().labels().list(userId='me').execute().get('labels', [])     label_ids = [label['id'] for label in updated_labels if label['name'] in labels_to_apply]          # Apply labels     service.users().messages().modify(         userId='me',         id=msg_id,         body={'addLabelIds': label_ids, 'removeLabelIds': ['UNREAD']}     ).execute()          # Optional: Forward email based on routing     # This part would connect to your forwarding logic          return {         'applied_labels': labels_to_apply,         'route_to': routing_info.get('route_to'),         'severity': routing_info.get('severity')     }  def main():     \"\"\"     Main function to orchestrate email processing     \"\"\"     # Authenticate     service = authenticate_gmail()          # Get unread emails     results = service.users().messages().list(         userId='me',          q='is:unread in:inbox'     ).execute()          messages = results.get('messages', [])          if not messages:         print(\"No unread messages found.\")         return          print(f\"Found {len(messages)} unread emails. Processing...\")          for message in messages:         # Get email content         email_data = get_email_content(service, message['id'])                  # Analyze with LLaMA         routing_info = analyze_with_llama(email_data['subject'], email_data['body'])                  # Apply routing decisions         result = apply_routing(service, email_data, routing_info)                  print(f\"Processed email: '{email_data['subject']}'\")         print(f\"  → Routed to: {result['route_to']}\")         print(f\"  → Severity: {result['severity']}\")         print(f\"  → Labels: {', '.join(result['applied_labels'])}\")         print(\"-\" * 50)  if __name__ == \"__main__\":     main()   Sample Prompt Sent to LLaMA   You are a smart email assistant.  Classify the following email and respond in JSON format with: 1. Who it should be routed to. 2. Severity level: Low, Medium, High, or Urgent.  Email: Subject:  Body:    This zero-shot prompt approach worked surprisingly well!   Why Not Just Rule-Based Filters?   Rule-based filters (like if subject contains “invoice” then forward) are brittle. They:      Miss context.   Fail on misspellings or vague language.   Don’t scale with varied email types.   Using LLaMA lets us handle:      Semantics (not just keywords)   Complex business logic   Adaptable rules based on intent   Final Thoughts   This project showed me how GenAI can elegantly solve boring but critical workflows. With just:      A Gmail API connection,   A local LLaMA model (via Ollama),   And some smart prompting…   …I built a system that’s capable of understanding and organizing email like a human assistant—but faster, and without ever needing coffee ☕.   Next steps?     🔁 Add scheduling   📊 Log and visualize routing stats   📥 Maybe even reply to some emails automatically…  ","categories": ["full-stack"],
        "tags": ["node js","security headers","web app","helmet","production"],
        "url": "/yashbhoomkar/full-stack/smart-email-routing/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "My Capgemini Internship Experience",
        "excerpt":"Introduction   From October 2024 to February 2025, I had the opportunity to intern with Capgemini’s GenAI team in Pune. Over the course of 4 months, I worked on building a unit test case curator for C and C++ codebases that leveraged Clang AST, Language Servers (LSP), and Generative AI.   The goal of the project was to boost developer productivity by creating a tool that could automatically generate meaningful unit test cases for any C/C++ function by analyzing the source code and passing relevant context to Capgemini’s GenAI engine.   Here’s a chronological log of the milestones achieved during my internship.   📅 Timeline of Work   ✅ 14 / 10 / 24 — Onboarding and Device Collection  On my first day, I completed all formalities related to onboarding. I was issued my work laptop and introduced to internal systems and tools at Capgemini.     ✅ 20 / 10 / 24 — Orientation and HR Activities  This day was dedicated to HR inductions, compliance training, and learning about Capgemini’s core values and culture. It was great to meet fellow interns and understand the scope of various verticals.     ✅ 24 / 10 / 24 — Manager Assignment Process  I was officially assigned to the GenAI team. I received the name of my reporting manager and was added to internal channels and sprint boards.     ✅ 01 / 11 / 24 — Project Knowledge Transfer (KT)  A colleague walked me through an existing prototype and explained Capgemini’s internal GenAI socket. We discussed expectations and the current state of the tooling.     ✅ 05 / 11 / 24 — Research: Regex-based Parsing  I initially explored using regular expressions to parse code and extract function details. This turned out to be fragile and error-prone for nested or complex C/C++ structures.     ✅ 11 / 11 / 24 — Research: GenAI-Based Context Extraction  Shifted focus toward using GenAI to understand code context instead of regexes. I started exploring how semantic understanding could make the tool more intelligent.     ✅ 15 / 11 / 24 — Manager Sync: My Approach Using AST  I pitched my idea of using Abstract Syntax Trees (AST) via Clang tooling to parse C/C++ functions and extract precise context. The manager gave green light to proceed.     ✅ 21 / 11 / 24 — Team Meeting: Tech Architecture  Presented a detailed technical architecture to the broader GenAI team, discussing how we’d gather function metadata, handle includes, dependencies, and socket communication.     ✅ 28 / 11 / 24 — Presentation: My Approach Walkthrough  I gave a structured walkthrough of my AST-based context extractor, demonstrating early results and how we’d connect it with the GenAI engine for test case generation.     ✅ 01 / 12 / 24 — Research: Clang AST  Deep-dived into Clang’s AST APIs, experimented with traversal techniques to extract function arguments, local variables, return types, and dependencies.     ✅ 10 / 12 / 24 — MVP Presentation  Presented the MVP of the Unit Test Curator Tool to my manager. It could now extract clean context blocks for individual functions and output them as structured data.     ✅ 15 / 12 / 24 — GenAI Socket Update  Collaborated with the core team to modify the socket protocol to better support test case suggestions and handle varied output lengths from the GenAI engine.     ✅ 01 / 01 / 25 — MVP Integration with Code Tester  We integrated the context-extraction module with Capgemini’s internal code-testing framework. Test cases were now being generated in real-time via the GenAI socket.     ✅ 15 / 01 / 25 — Final Tool Integration with GenAI Socket  The full pipeline was in place: from AST context extraction → passing to GenAI → receiving test cases → injecting into testing scaffolds. The tool was ready for team-wide use.     ✅ 01 / 02 / 25 — Final Testing &amp; Debugging  Conducted thorough debugging and ran validations on 100+ C/C++ functions. Edge cases, macros, and template handling were tested and optimized.     ✅ 10 / 02 / 25 — Final Demo to Senior Director  I showcased the tool in a final demo session to Capgemini’s Senior Director. Received great feedback on the real-world productivity boost the tool offered to developers.     ✅ 13 / 02 / 25 — Last Day and Device Handover  Wrapped up all documentation, submitted my project report, and returned the device. A wonderful learning journey came to an end. ✨     🧠 Tech Stack &amp; Tools Used      Languages: Python, C++   Compiler Tools: Clang, LibTooling   AST Parsing: Clang Python Bindings   GenAI Integration: Capgemini GenAI Socket   Code Analysis: Language Server Protocol (LSP)   Internal Testing Frameworks     Final Thoughts   This internship at Capgemini was more than just a corporate stint—it was an intense learning experience. I got hands-on with real-world GenAI applications, explored compiler internals, and improved my understanding of scalable tooling for enterprise codebases.   The project taught me how traditional techniques like ASTs can work hand-in-hand with next-gen GenAI models to solve developer problems more intelligently.   I’m incredibly grateful to my manager and team for the support and the freedom to explore ideas. Looking forward to what comes next! 🚀  ","categories": ["full-stack"],
        "tags": ["genai","clang","ast","capgemini","productivity","python","lsp","unit-testing"],
        "url": "/yashbhoomkar/full-stack/capgemini-internship-experience/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "Process Scheduling Algorithms in Operating Systems",
        "excerpt":"🧠 Introduction   In a multitasking operating system, process scheduling is the key to managing how the CPU is shared among multiple processes.      A scheduler decides which process gets the CPU, for how long, and in what order.    This blog breaks down the most common scheduling algorithms in OS: FIFO, Round Robin, SJF, Priority, and Multilevel Queue.     ⚙️ Terminologies First      Burst Time (BT): Time a process needs on the CPU   Arrival Time (AT): When the process enters the ready queue   Waiting Time (WT): Time process waits in the queue   Turnaround Time (TAT): Time from arrival to completion  &gt; TAT = Completion Time - Arrival Time  &gt; WT = TAT - Burst Time     1️⃣ FIFO / FCFS (First Come First Serve)   Concept: Processes are scheduled in the order they arrive.                  Pros       Cons                       Simple       Convoy effect: long processes delay short ones                 Fair in order       Poor average waiting time           📝 Example: Arrival: P1, P2, P3 BT: 4 3 2 → Order: P1 → P2 → P3   yaml Copy Edit     2️⃣ SJF (Shortest Job First)   Concept: Schedule the process with the smallest burst time first.                  Pros       Cons                       Optimal avg WT       Starvation of long processes                         Requires BT prediction           📝 Example: BT: P1=6, P2=2, P3=1 → Order: P3 → P2 → P1   yaml Copy Edit     3️⃣ Round Robin (RR)   Concept: Each process gets a fixed time slice (quantum), then moves to the back of the queue.                  Pros       Cons                       Fair CPU sharing       Depends on quantum size                 Great for time-sharing       High context switch overhead           📝 Example (Quantum = 2):   Queue: P1=4, P2=3, P3=5 Cycle: P1(2) → P2(2) → P3(2) → P1(2) → P2(1) → P3(3)   yaml Copy Edit     4️⃣ Priority Scheduling   Concept: Each process has a priority. Highest priority runs first.                  Pros       Cons                       Flexible control       Starvation of low priority                 Great for real-time apps       Aging needed to prevent starvation           📝 Example: Priorities: P1=3, P2=1, P3=2 → Order: P2 → P3 → P1   yaml Copy Edit     5️⃣ Multilevel Queue Scheduling   Concept: Processes are grouped (interactive, batch, etc.) and each group has its own scheduling algorithm.      Each queue has different priority.   No process moves between queues (static).   RR can be used inside queues.   🧠 Useful for systems with distinguished process types.     📊 Comparison Table                  Algorithm       Preemptive       Starvation Possible       Best For                       FCFS       ❌       ❌       Simplicity                 SJF       ❌/✅       ✅       Batch systems                 Round Robin       ✅       ❌       Time-sharing systems                 Priority       ✅       ✅       Real-time systems                 Multilevel       ✅/❌       Depends       Complex environments             🧪 Pro Tip: Visualizing With Gantt Charts   When practicing scheduling questions, always draw a Gantt chart to understand execution flow and calculate:      Completion Time (CT)   Waiting Time (WT)   Turnaround Time (TAT)     💡 Final Thoughts   Understanding process scheduling is core to operating systems and is often asked in interviews and exams.   Each algorithm is designed for specific use cases — there’s no one-size-fits-all. It’s all about choosing the right tool for the job!   Want a post covering Deadlocks, Memory Management, or Page Replacement Algorithms next? Let me know 💡  ","categories": ["operating systems"],
        "tags": ["os","scheduling","round robin","fifo","sjf","priority","cpu","interview"],
        "url": "/yashbhoomkar/operating%20systems/process-scheduling-algorithms/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      },{
        "title": "Smart Expense Manager & Auto-Budgeting with Telegram + Gemini AI",
        "excerpt":"💡 Introduction   Managing expenses shouldn’t feel like managing a spreadsheet. That’s what drove the idea behind Smart Expense Manager — a conversational, intelligent solution for personal and group expense tracking, built using Telegram, Razorpay, Gemini AI, and MongoDB.   This was my hackathon entry for a software innovation challenge — and it turned into one of the most fun and useful projects I’ve built!     🧠 What the System Does      “A Telegram message is all it takes.”    This smart assistant helps users:     📥 Log expenses easily from chat   👥 Split bills with friends in real-time   🤖 Use AI to suggest budgets based on spending   💰 Handle payments using Razorpay   📲 Get alerts via SMS   All without ever leaving Telegram.     🛠️ Tech Stack                  Layer       Stack Used                       Frontend       Telegram Chat UI                 Backend       Node.js + Express                 AI Engine       Gemini API (Google AI)                 Database       MongoDB Atlas                 Payments       Razorpay Integration                 Alerts       Twilio SMS / Bot API             🧱 Architecture Overview      User sends command to the Telegram bot (/add, /split, /view, /suggest)   Bot sends the data to a Node.js backend   User data, group metadata, and expenses are stored in MongoDB   The backend:            Calls Gemini AI to suggest budgeting categories and limits       Calls Razorpay API to send payment links if needed       Sends SMS reminders through Twilio           User receives updates — budget suggestions, summaries, and payment confirmations — right inside Telegram.     🔑 Core Features   1. 💬 Telegram Chat Bot     Intuitive chat-first interface   Expense logging in seconds   Group creation &amp; invite support   2. 🧠 Gemini AI Budgeting     Analyzes past spend data   Recommends monthly budget goals   Adjusts based on user behavior   3. 💸 Razorpay Integration     Real-time request-to-pay system   Pings payer via UPI or card   Confirms payments instantly   4. 📢 Alerts via SMS / Telegram     Sends transaction confirmations   Daily/weekly budget digests   Payment reminders     💼 Example Use Case   You enter: ```bash /split Pizza 1200 with @rohan @raj @meena ➡️ The bot:   Splits amount ₹300 each   Sends Razorpay requests   Logs in MongoDB   Notifies users via SMS + bot chat   🔮 Future Scope Voice-command support with Google Assistant   Expense forecasting with ML   Integration with bank APIs   Android/iOS native companion app   Leaderboard of budgeters (gamification)   ✨ Takeaway This project helped me explore:   Real-time APIs and integrations   Multi-user concurrency via chatbots   Payment flow design   AI-in-the-loop systems   It’s the perfect example of how GenAI + full-stack dev can create delightful user experiences — that are actually useful.   ","categories": ["full-stack"],
        "tags": ["telegram bot","gemini","razorpay","mongodb","ai","expense tracker","budgeting"],
        "url": "/yashbhoomkar/full-stack/smart-expense-manager/",
        "teaser": "/yashbhoomkar/assets/images/teaser.jpg"
      }]
